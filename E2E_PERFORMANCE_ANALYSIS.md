# 🚀 E2E 성능 벤치마크 분석 보고서

**생성일시**: 2025-12-17  
**테스트 환경**: Docker Compose (Backend + Postgres + Redis + Elasticsearch)  
**테스트 대상**: 채팅 에이전트 시스템 (`/api/chat` 엔드포인트)

---

## 📊 핵심 결과

### 응답 시간 비교

| 지표 | MCP 개별 호출 | E2E 전체 응답 | 증가율 |
|------|-------------|-------------|--------|
| **평균** | 501ms | 16,627ms | **+3219%** |
| **중앙값** | 428ms | 12,642ms | **+2854%** |
| **P95** | 756ms | 30,349ms | **+3914%** |
| **범위** | 387~756ms | 5,863~30,349ms | - |

**결론**: E2E 응답시간이 MCP 개별 호출보다 **약 33배 느림**

---

## 🔍 성능 오버헤드 분석

### 시간 구성 (E2E 평균 16,627ms)

```
E2E 총 시간: 16,627ms
├─ Agent 루프 오버헤드: 16,126ms (97.0%) ← 병목
│  ├─ Claude API 호출 (토큰 수, 모델 응답 시간)
│  ├─ 프롬프트 구성 및 파싱
│  ├─ 도구 호출 디스패칭 및 JSON 직렬화
│  └─ 결과 집계 및 최종 응답 구성
└─ MCP 도구 실제 호출: 501ms (3.0%)
   ├─ Curriculum: 395ms (가장 빠름)
   ├─ Library: 415ms
   ├─ Meal: 425ms
   ├─ Classroom: 639ms
   └─ Notice: 679ms (가장 느림)
```

### 주요 인사이트

1. **Claude API가 주요 병목** (97% 오버헤드)
   - 각 프롬프트 완성 요청이 5~15초 소요
   - 도구 호출 후 재요청 시 누적 지연

2. **순차 도구 호출의 누적 효과**
   - Agent가 한 번에 하나의 도구를 호출하고 결과를 기다림
   - 여러 도구가 필요한 경우 (예: 교과과정 + 공지사항) 지연 가중

3. **MCP 프로세스 생성 비용**
   - 각 MCP 호출마다 Python 서브프로세스 생성
   - 개별 호출 500ms 중 일부는 프로세스 오버헤드

---

## 📋 쿼리 유형별 응답 시간

### 분류

| 유형 | 호출 수 | 평균 | 범위 | 특징 |
|------|--------|------|------|------|
| **간단한 QA** | 1 | 7,797ms | - | LLM만 사용, 도구 X |
| **인사/감사** | 2 | 6,051ms | 5.9~6.2s | 최소 지연 |
| **학식/장학금** | 2 | 9,579ms | 8.5~10.7s | 단일 MCP 호출 |
| **공지사항** | 1 | 12,642ms | - | Notice MCP (679ms) 포함 |
| **강의실** | 2 | 16,078ms | 10.9~21.3s | Classroom/위치 검색 조합 |
| **복합/추천** | 2 | 23,129ms | 19.1~27.1s | 다중 도구 호출 |
| **교과과정** | 2 | 27,864ms | 25.4~30.3s | 느린 Curriculum MCP + 재호출 |
| **도서관** | 1 | 30,313ms | - | 가장 느림 (로그인 재시도?) |

### 패턴

```
응답 시간 = 베이스 (Claude API) + Σ(각 MCP 호출 시간)

예:
- "안녕하세요" → 베이스만 → ~6s
- "최신 공지사항" → 베이스 + Notice MCP (679ms) → ~12.6s
- "도서관 좌석" → 베이스 + Library MCP (415ms) + 재호출 → ~30s
```

---

## 🎯 MCP 서버별 성능

### 개별 호출 속도 (3회 반복 평균)

```
Curriculum:  395ms ✅ (가장 빠름, 안정적)
Library:     415ms
Meal:        425ms
Classroom:   639ms (불안정, 1회 실패)
Notice:      679ms ❌ (가장 느림)
```

### 느린 MCP 분석

**Notice MCP (679ms)**
- 웹 크롤링 기반 (BeautifulSoup)
- 네트워크 지연 + DOM 파싱 포함
- 문제: 교내 서버/방화벽 제약?

**Classroom MCP (639ms)**
- 불안정성 (15회 중 1회 실패)
- 데이터베이스 쿼리 다중화 가능성

---

## 💡 성능 최적화 방안

### 단기 개선 (1~2일)

1. **MCP 병렬 호출**
   ```python
   # 현재: 순차 호출
   classroom_result = await mcp_call("classroom", ...)
   curriculum_result = await mcp_call("curriculum", ...)  # 기다려야 함
   
   # 개선: 병렬 호출
   results = await asyncio.gather(
       mcp_call("classroom", ...),
       mcp_call("curriculum", ...)
   )
   ```
   - **예상 개선**: 20~30% 응답시간 단축

2. **MCP 프로세스 풀 재사용**
   ```python
   # 현재: 매 호출마다 subprocess 생성
   # 개선: 상시 실행 MCP 서버, HTTP/gRPC 호출
   ```
   - **예상 개선**: 10~15% (프로세스 생성 오버헤드 제거)

3. **Redis 캐싱 확대**
   - 공지사항 캐시 (TTL 1시간)
   - 교과과정 캐시 (TTL 2시간)
   - 식단 캐시 (TTL 30분)
   - **예상 개선**: 반복 쿼리 80% 단축

### 중기 개선 (1주)

4. **Agent 구조 최적화**
   - 초기 프롬프트에서 필요한 도구 선별
   - 불필요한 재호출 방지
   - **예상 개선**: 15~25% (Claude API 호출 횟수 감소)

5. **SLM (작은 언어 모델) 2단계 구조**
   ```
   입력 → SLM (의도 분류) → 특화 처리
   ```
   - 간단한 QA는 SLM에서 처리 (응답: ~100ms)
   - 복잡한 쿼리만 Claude 사용
   - **예상 개선**: 40~60% (간단한 쿼리 응답시간)

### 장기 개선 (2주+)

6. **MCP 서버 최적화**
   - Notice 웹 크롤러 → Playwright 병렬화
   - Curriculum DB 인덱싱 및 쿼리 최적화
   - Classroom 불안정성 원인 조사

7. **배포 아키텍처 개선**
   - MCP 서버 독립 프로세스/컨테이너화
   - Load Balancer (라운드 로빈)
   - CDN/캐시 레이어 추가

---

## 🔧 현재 시스템 구성

### 성능 특성

| 구성요소 | 특징 | 성능 영향 |
|---------|------|---------|
| **Agent** | Claude Sonnet-4, max_iterations=3 | 기본 5~6초 |
| **MCP** | 순차 호출, 프로세스 기반 | +3~7초 |
| **LLM** | 토큰 완성 시간 (스트리밍 X) | +5~15초 |
| **Cache** | Redis (1시간 TTL) | 옵션 |
| **Database** | SQLite (로컬 테스트) → Postgres (운영) | 주변 영향 |

### 병목 순서

1. **Claude API (97%)** ← 주요 개선 대상
2. MCP 호출 (3%)
3. 네트워크 (포함됨)
4. 데이터베이스 (포함됨)

---

## 📈 개선 효과 시뮬레이션

### 시나리오: 모든 최적화 적용 시

```
현재 상태:
  간단한 QA: ~7s  (베이스만)
  도구 1개: ~12s  (베이스 + MCP)
  도구 2개+: ~23s (베이스 + 다중 MCP)

병렬 호출 적용 후:
  도구 2개+: ~16s (2개 동시 호출) -30%

SLM + 캐싱 적용 후:
  간단한 QA: ~1s  (SLM) -85%
  도구 1개: ~6s   (캐시 히트) -50%
  도구 2개+: ~12s (병렬) -48%

최종 예상 (베이스라인 기준):
  간단한 QA: 7s → 1s (-85%)
  도구 1개: 12s → 6s (-50%)
  도구 2개+: 23s → 12s (-48%)
```

---

## ✅ 다음 단계

### 즉시 (오늘)
- [ ] 병렬 호출 구현 테스트
- [ ] 캐싱 TTL 증가

### 단기 (3일)
- [ ] SLM 의도 분류기 구현
- [ ] MCP 프로세스 풀 설계

### 중기 (1주)
- [ ] Notice MCP 웹 크롤러 최적화
- [ ] 배포 구조 검토

---

## 📊 벤치마크 파일

- **MCP 개별**: `logs/mcp_benchmark_20251217_010913.json`
- **E2E 전체**: `logs/e2e_latency_20251217_011736.json`
- **비교 분석**: `logs/benchmark_analysis.txt`

---

**결론**: 
현재 E2E 응답시간의 97%는 **Claude API 호출 오버헤드**입니다.  
MCP 서버 최적화도 중요하지만, **Agent 구조 개선**이 가장 큰 효과를 가져올 것 같습니다.

특히 **병렬 도구 호출**과 **의도 기반 라우팅**을 통해  
**30~50% 응답시간 단축**이 현실적으로 가능합니다.
