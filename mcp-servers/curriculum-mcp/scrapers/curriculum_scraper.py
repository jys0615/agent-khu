#!/usr/bin/env python3
"""
Curriculum Scraper - ê³¼ëª© ì¹´íƒˆë¡œê·¸ + ì¡¸ì—…ìš”ê±´ í†µí•©
"""
from __future__ import annotations
import re
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict

import requests
from lxml import html as lxml_html

# ì €ì¥ ê²½ë¡œ
DATA_PATH = Path(__file__).resolve().parent.parent / "data" / "curriculum_data.json"
REQUIREMENTS_SCRAPER_PATH = Path(__file__).resolve().parent / "requirements_scraper.py"


def scrape_ce_curriculum(url: str = "https://ce.khu.ac.kr/ce/user/contents/view.do?menuNo=1600054") -> dict:
    """ì»´í“¨í„°ê³µí•™ê³¼ êµê³¼ê³¼ì • í¬ë¡¤ë§ - ì •í™•í•œ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì‚¬ìš©"""
    print(f"ğŸ”„ í¬ë¡¤ë§ ì‹œì‘: {url}")
    
    try:
        resp = requests.get(url, timeout=15)
        resp.raise_for_status()
        
        doc = lxml_html.fromstring(resp.text)
        tables = doc.xpath("//table")
        
        catalog = []
        
        for table in tables:
            rows = table.xpath(".//tr")
            if len(rows) < 2:
                continue
            
            # í—¤ë” í™•ì¸
            header = rows[0]
            headers = [td.text_content().strip() for td in header.xpath(".//th|.//td")]
            header_text = " ".join(headers)
            
            # êµê³¼ëª© í…Œì´ë¸”ì¸ì§€ í™•ì¸
            if not any(kw in header_text for kw in ["êµê³¼ëª©", "í•™ìˆ˜ë²ˆí˜¸", "í•™ì "]):
                continue
            
            print(f"\nâœ… êµê³¼ëª© í…Œì´ë¸” ë°œê²¬!")
            print(f"ğŸ“‹ í—¤ë”: {headers[:15]}")
            
            # ë°ì´í„° íŒŒì‹±
            last_group = ""  # rowspan ì²˜ë¦¬ìš©
            
            for idx, row in enumerate(rows[1:]):
                cells = [td.text_content().strip() for td in row.xpath(".//td")]
                
                if len(cells) < 4:
                    continue
                
                try:
                    # rowspan ê°ì§€: 15ê°œë©´ ì •ìƒ, 14ê°œë©´ rowspan ì¤‘
                    has_group_col = (len(cells) >= 15)
                    
                    if has_group_col:
                        # ì •ìƒ í–‰ (ì´ìˆ˜êµ¬ë¶„ í¬í•¨)
                        group = cells[1]
                        name = cells[2]
                        code = cells[3]
                        credits_str = cells[4]
                        sem1_idx = 10
                        sem2_idx = 11
                        last_group = group  # ì €ì¥
                    else:
                        # rowspan í–‰ (ì´ìˆ˜êµ¬ë¶„ ìƒëµë¨)
                        group = last_group  # ì´ì „ ê°’ ì‚¬ìš©
                        name = cells[1]     # í•œ ì¹¸ ì•ìœ¼ë¡œ
                        code = cells[2]
                        credits_str = cells[3]
                        sem1_idx = 9        # í•œ ì¹¸ ì•ìœ¼ë¡œ
                        sem2_idx = 10
                    
                    # ë””ë²„ê·¸ (ì²˜ìŒ 10ê°œë§Œ)
                    if idx < 10:
                        print(f"\nğŸ” Row {idx+1}: cells={len(cells)}ê°œ, rowspan={'ì—†ìŒ' if has_group_col else 'ì ìš©ì¤‘'}")
                        print(f"   ì´ìˆ˜êµ¬ë¶„: {group}")
                        print(f"   êµê³¼ëª©ëª…: {name}")
                        print(f"   í•™ìˆ˜ë²ˆí˜¸: {code}")
                        print(f"   í•™ì : {credits_str}")
                        if len(cells) > sem1_idx:
                            print(f"   [{sem1_idx}] 1í•™ê¸°: '{cells[sem1_idx]}'")
                        if len(cells) > sem2_idx:
                            print(f"   [{sem2_idx}] 2í•™ê¸°: '{cells[sem2_idx]}'")
                    
                    # í•™ì  íŒŒì‹±
                    credits = 3
                    try:
                        match = re.search(r'\d+', credits_str)
                        if match:
                            credits = int(match.group())
                    except:
                        pass
                    
                    # í•™ê¸° ì •ë³´
                    semesters = []
                    if len(cells) > sem1_idx and "â—‹" in cells[sem1_idx]:
                        semesters.append("1")
                    if len(cells) > sem2_idx and "â—‹" in cells[sem2_idx]:
                        semesters.append("2")
                    
                    # ìœ íš¨ì„±
                    if not code or not name:
                        continue
                    
                    item = {
                        "code": code,
                        "name": name,
                        "credits": credits,
                        "group": group,
                        "semesters": semesters
                    }
                    
                    catalog.append(item)
                    
                    if idx < 10:
                        print(f"   âœ… íŒŒì‹± ì™„ë£Œ: code={code}, name={name}, semesters={semesters}")
                
                except Exception as e:
                    if idx < 10:
                        print(f"   âŒ ì—ëŸ¬: {e}")
                        import traceback
                        traceback.print_exc()
                    continue
        
        print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(catalog)}ê°œ ê³¼ëª©")
        
        # ìë£Œêµ¬ì¡° í™•ì¸
        for item in catalog:
            if item["code"] == "CSE204":
                print(f"\nğŸ¯ ìë£Œêµ¬ì¡° ë°œê²¬: {json.dumps(item, ensure_ascii=False, indent=2)}")
                break
        
        return {
            "year": "2024",
            "catalog": catalog,
            "crawled_at": datetime.now().isoformat()
        }
    
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {}


def save_data(data: dict) -> None:
    """ë°ì´í„° ì €ì¥"""
    DATA_PATH.parent.mkdir(parents=True, exist_ok=True)
    
    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {DATA_PATH}")


def main():
    """ë©”ì¸ ì‹¤í–‰ - ê³¼ëª© ì¹´íƒˆë¡œê·¸ + ì¡¸ì—…ìš”ê±´ í†µí•©"""
    print("ğŸ”„ ì»¤ë¦¬í˜ëŸ¼ ì „ì²´ ë°ì´í„° ê°±ì‹  ì‹œì‘...\n")
    
    # 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_data = {}
    if DATA_PATH.exists():
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            existing_data = json.load(f)
        print("âœ… ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    # 2. ê³¼ëª© ì¹´íƒˆë¡œê·¸ í¬ë¡¤ë§ (2024ë…„ë§Œ ìƒˆë¡œ í¬ë¡¤ë§)
    print("\nğŸ“š ê³¼ëª© ì¹´íƒˆë¡œê·¸ í¬ë¡¤ë§...")
    new_catalog = scrape_ce_curriculum()
    
    if not new_catalog or not new_catalog.get("catalog"):
        print("âš ï¸ ê³¼ëª© í¬ë¡¤ë§ ì‹¤íŒ¨ - ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")
        new_catalog = existing_data.get("2024", {})
    else:
        print(f"âœ… {len(new_catalog['catalog'])}ê°œ ê³¼ëª© ì¶”ì¶œ")
    
    # 3. ì¡¸ì—…ìš”ê±´ í¬ë¡¤ë§ (requirements_scraper í˜¸ì¶œ)
    print("\nğŸ“‹ ì¡¸ì—…ìš”ê±´ ë°ì´í„° í¬ë¡¤ë§...")
    try:
        import sys
        sys.path.insert(0, str(REQUIREMENTS_SCRAPER_PATH.parent))
        from requirements_scraper import scrape_requirements, merge_requirements_with_catalog
        
        # ì»´í“¨í„°ê³µí•™ê³¼ ìš”ê±´ í¬ë¡¤ë§
        req_data = scrape_requirements("ce")
        
        if req_data:
            print(f"âœ… ì¡¸ì—…ìš”ê±´ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ ({len(req_data['requirements'])}ê°œ ì—°ë„)")
            # ê¸°ì¡´ ë°ì´í„°ì™€ í†µí•©
            final_data = merge_requirements_with_catalog(existing_data, req_data)
        else:
            print("âš ï¸ ì¡¸ì—…ìš”ê±´ í¬ë¡¤ë§ ì‹¤íŒ¨ - ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")
            final_data = existing_data
    
    except Exception as e:
        print(f"âš ï¸ ì¡¸ì—…ìš”ê±´ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        final_data = existing_data
    
    # 4. ì €ì¥
    DATA_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    
    print("\n" + "="*60)
    print(f"âœ… ì „ì²´ ì‘ì—… ì™„ë£Œ")
    print(f"   - ê³¼ëª©: {len(new_catalog.get('catalog', []))}ê°œ")
    print(f"   - ì €ì¥ ê²½ë¡œ: {DATA_PATH}")
    print("="*60)


if __name__ == "__main__":
    main()