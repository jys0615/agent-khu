name: Daily Finetune

on:
  workflow_dispatch:
  schedule:
    - cron: "0 18 * * *"

jobs:
  finetune:
    runs-on: ubuntu-latest
    timeout-minutes: 480

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -U transformers accelerate peft datasets sentencepiece protobuf elasticsearch

      - name: Extract training data
        working-directory: backend/scripts
        continue-on-error: true
        run: python3 extract_training_data.py

      - name: Create dummy training data if needed
        working-directory: backend/scripts
        run: |
          if [ ! -f training_data.jsonl ]; then
            python3 -c "
          import json
          data = [
            {'instruction': '경희대학교 정보', 'input': '알고리즘 몇 학점?', 'output': '3학점', 'tools_used': [], 'metadata': {}},
            {'instruction': '경희대학교 정보', 'input': '자료구조 언제?', 'output': '1,2학기', 'tools_used': [], 'metadata': {}},
            {'instruction': '경희대학교 정보', 'input': '운영체제?', 'output': '선택', 'tools_used': [], 'metadata': {}}
          ]
          with open('training_data.jsonl', 'w') as f:
            for item in data:
              f.write(json.dumps(item, ensure_ascii=False) + '\n')
            "
          fi
          wc -l training_data.jsonl

      - name: Run finetune
        working-directory: backend/scripts
        run: python3 finetune_slm.py

      - name: Upload artifacts
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: finetuned-model
          path: models/finetuned/
