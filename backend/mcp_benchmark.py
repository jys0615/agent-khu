import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
from statistics import mean, stdev, median
import sys

# Ensure backend package is importable
BASE_DIR = Path(__file__).resolve().parent
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

from app.mcp_client import mcp_client


# ê° MCP ì„œë²„ë³„ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (name, tool, args)
MCP_TESTS = {
    "classroom": [
        ("search_classroom", {"query": "101í˜¸"}),
        ("search_classroom", {"query": "312"}),
        ("search_classroom", {"query": "ê°•ì˜ì‹¤"}),
    ],
    "notice": [
        ("search_notices", {"query": "ì¥í•™", "limit": 3}),
        ("search_notices", {"query": "ê³µì§€", "limit": 5}),
        ("search_notices", {"query": "ì‹ ì²­", "limit": 3}),
    ],
    "meal": [
        ("get_today_meal", {"meal_type": "lunch"}),
        ("get_today_meal", {"meal_type": "breakfast"}),
        ("get_today_meal", {"meal_type": "dinner"}),
    ],
    "library": [
        ("get_library_info", {"campus": "global"}),
        ("get_library_info", {"campus": "global"}),
        ("get_library_info", {"campus": "global"}),
    ],
    "curriculum": [
        ("search_curriculum", {"query": "ìë£Œêµ¬ì¡°", "year": "2024"}),
        ("search_curriculum", {"query": "í”„ë¡œê·¸ë˜ë°", "year": "2024"}),
        ("search_curriculum", {"query": "AI", "year": "2024"}),
    ],
}


async def measure_mcp_call(server: str, tool: str, args: dict, timeout: float = 5.0) -> dict:
    """ë‹¨ì¼ MCP í˜¸ì¶œ ì¸¡ì •"""
    start = time.perf_counter()
    try:
        result = await mcp_client.call_tool(server, tool, args, timeout=timeout, retries=0)
        elapsed_ms = int((time.perf_counter() - start) * 1000)
        
        # ê²°ê³¼ í¬ê¸° ì¸¡ì •
        try:
            payload_size = len(json.dumps(result, ensure_ascii=False))
        except Exception:
            payload_size = 0
        
        return {
            "server": server,
            "tool": tool,
            "success": True,
            "latency_ms": elapsed_ms,
            "payload_size": payload_size,
        }
    except Exception as e:
        elapsed_ms = int((time.perf_counter() - start) * 1000)
        return {
            "server": server,
            "tool": tool,
            "success": False,
            "latency_ms": elapsed_ms,
            "error": str(e)[:100],
        }


async def main():
    """MCP ì„œë²„ë³„ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    all_results = []
    
    # ê° ì„œë²„ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    for server, tests in MCP_TESTS.items():
        print(f"\nğŸ”§ {server.upper()} MCP ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
        server_results = []
        
        for tool, args in tests:
            print(f"  â–¸ {tool}({json.dumps(args)})...", end=" ", flush=True)
            result = await measure_mcp_call(server, tool, args)
            server_results.append(result)
            all_results.append(result)
            
            status = "âœ…" if result["success"] else "âŒ"
            print(f"{status} {result['latency_ms']}ms")
    
    # í†µê³„ ê³„ì‚°
    by_server = {}
    for server in MCP_TESTS.keys():
        server_calls = [r for r in all_results if r["server"] == server]
        success_calls = [r for r in server_calls if r["success"]]
        
        if success_calls:
            latencies = [r["latency_ms"] for r in success_calls]
            by_server[server] = {
                "total": len(server_calls),
                "success": len(success_calls),
                "failed": len(server_calls) - len(success_calls),
                "avg_latency_ms": int(mean(latencies)),
                "median_latency_ms": int(median(latencies)),
                "min_latency_ms": min(latencies),
                "max_latency_ms": max(latencies),
                "stdev_latency_ms": int(stdev(latencies)) if len(latencies) > 1 else 0,
                "p95_latency_ms": int(sorted(latencies)[int(len(latencies) * 0.95)] if len(latencies) > 1 else latencies[0]),
            }
        else:
            by_server[server] = {
                "total": len(server_calls),
                "success": 0,
                "failed": len(server_calls),
                "error": "ëª¨ë“  í˜¸ì¶œ ì‹¤íŒ¨"
            }
    
    # ì „ì²´ í†µê³„
    success_all = [r for r in all_results if r["success"]]
    if success_all:
        all_latencies = [r["latency_ms"] for r in success_all]
        summary = {
            "generated_at": datetime.now().isoformat(),
            "total": len(all_results),
            "success": len(success_all),
            "failed": len(all_results) - len(success_all),
            "avg_latency_ms": int(mean(all_latencies)),
            "median_latency_ms": int(median(all_latencies)),
            "min_latency_ms": min(all_latencies),
            "max_latency_ms": max(all_latencies),
            "stdev_latency_ms": int(stdev(all_latencies)) if len(all_latencies) > 1 else 0,
        }
    else:
        summary = {
            "generated_at": datetime.now().isoformat(),
            "total": len(all_results),
            "success": 0,
            "failed": len(all_results),
            "error": "ëª¨ë“  í˜¸ì¶œ ì‹¤íŒ¨"
        }
    
    # íŒŒì¼ ì €ì¥
    logs_dir = BASE_DIR.parent / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    out_json = logs_dir / f"mcp_benchmark_{ts}.json"
    with open(out_json, "w", encoding="utf-8") as f:
        json.dump({
            "summary": summary,
            "by_server": by_server,
            "all_calls": all_results
        }, f, ensure_ascii=False, indent=2)
    
    # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
    out_txt = logs_dir / f"mcp_benchmark_{ts}.txt"
    lines = [
        "=" * 70,
        "MCP ì„œë²„ë³„ í‰ê·  ì‘ë‹µì‹œê°„ ë²¤ì¹˜ë§ˆí¬",
        "=" * 70,
        f"ìƒì„±ì¼ì‹œ: {summary['generated_at']}",
        f"ì´ í˜¸ì¶œ: {summary['total']}, ì„±ê³µ: {summary['success']}, ì‹¤íŒ¨: {summary['failed']}",
        "",
        "ğŸ“Š ì „ì²´ í†µê³„",
        f"  í‰ê· : {summary.get('avg_latency_ms', 'N/A')}ms",
        f"  ì¤‘ì•™ê°’: {summary.get('median_latency_ms', 'N/A')}ms",
        f"  ìµœì†Œ: {summary.get('min_latency_ms', 'N/A')}ms",
        f"  ìµœëŒ€: {summary.get('max_latency_ms', 'N/A')}ms",
        f"  í‘œì¤€í¸ì°¨: {summary.get('stdev_latency_ms', 'N/A')}ms",
        "",
        "ğŸ“ˆ ì„œë²„ë³„ ìƒì„¸ í†µê³„",
    ]
    
    for server in sorted(by_server.keys()):
        stats = by_server[server]
        if "error" in stats:
            lines.append(f"\n{server.upper()}: {stats['error']}")
        else:
            lines.append(f"\n{server.upper()}")
            lines.append(f"  í˜¸ì¶œ: {stats['total']} (ì„±ê³µ: {stats['success']}, ì‹¤íŒ¨: {stats['failed']})")
            lines.append(f"  í‰ê· : {stats['avg_latency_ms']}ms")
            lines.append(f"  ì¤‘ì•™ê°’: {stats['median_latency_ms']}ms")
            lines.append(f"  ë²”ìœ„: {stats['min_latency_ms']}ms ~ {stats['max_latency_ms']}ms")
            lines.append(f"  P95: {stats['p95_latency_ms']}ms")
            lines.append(f"  í‘œì¤€í¸ì°¨: {stats['stdev_latency_ms']}ms")
    
    lines.append("")
    lines.append("=" * 70)
    lines.append("ìƒì„¸ í˜¸ì¶œ ê¸°ë¡")
    lines.append("=" * 70)
    for call in all_results:
        status = "âœ…" if call["success"] else "âŒ"
        if call["success"]:
            lines.append(f"{status} {call['server']}.{call['tool']}: {call['latency_ms']}ms (í¬ê¸°: {call['payload_size']} bytes)")
        else:
            lines.append(f"{status} {call['server']}.{call['tool']}: {call['error']}")
    
    out_txt.write_text("\n".join(lines), encoding="utf-8")
    
    print(f"\nâœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    print(f"ğŸ“„ JSON: {out_json}")
    print(f"ğŸ“„ í…ìŠ¤íŠ¸: {out_txt}")
    print(f"\nğŸ¯ ìš”ì•½:")
    print(f"   ì´ í˜¸ì¶œ: {summary['total']}, ì„±ê³µ: {summary['success']}, ì‹¤íŒ¨: {summary['failed']}")
    print(f"   í‰ê·  ì‘ë‹µ: {summary.get('avg_latency_ms', 'N/A')}ms")
    print(f"   ë²”ìœ„: {summary.get('min_latency_ms', 'N/A')}ms ~ {summary.get('max_latency_ms', 'N/A')}ms")


if __name__ == "__main__":
    asyncio.run(main())
