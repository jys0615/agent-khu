"""
ì¢…í•© ì„±ëŠ¥ ì§€í‘œ ì¸¡ì •
1. Tool í˜¸ì¶œ ì„±ê³µë¥  (ë„êµ¬ë³„)
2. ìºì‹œ ì ì¤‘ë¥  (Redis)
3. ì¡¸ì—…ìš”ê±´ í™•ì¸ ì‘ë‹µ ì‹œê°„ (íŠ¹í™” ì¿¼ë¦¬)
4. íƒ€ì„ì•„ì›ƒ/ì˜¤ë¥˜ìœ¨
"""
import asyncio
import aiohttp
import json
import time
import redis
from datetime import datetime
from pathlib import Path
from statistics import mean, stdev, median
from typing import Dict, List

# íŠ¹í™” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
SPECIALIZED_QUERIES = [
    # ì¡¸ì—…ìš”ê±´
    ("ì¡¸ì—…ìš”ê±´_1", "2024í•™ë²ˆ ì»´í“¨í„°ê³µí•™ë¶€ ì¡¸ì—…ìš”ê±´ì€?"),
    ("ì¡¸ì—…ìš”ê±´_2", "ì¡¸ì—…ê¹Œì§€ ëª‡ í•™ì  í•„ìš”í•´?"),
    
    # ìºì‹œ ì ì¤‘ í…ŒìŠ¤íŠ¸ (ê°™ì€ ì¿¼ë¦¬ ë°˜ë³µ)
    ("ìºì‹œ_1íšŒì°¨_1", "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ë­ì•¼?"),
    ("ìºì‹œ_1íšŒì°¨_2", "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ë­ì•¼?"),
    ("ìºì‹œ_1íšŒì°¨_3", "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ë­ì•¼?"),
    
    # ê³µì§€ì‚¬í•­ ìºì‹œ í…ŒìŠ¤íŠ¸
    ("ìºì‹œ_ê³µì§€_1", "ìµœì‹  ê³µì§€ì‚¬í•­ì„ ë³´ì—¬ì¤˜"),
    ("ìºì‹œ_ê³µì§€_2", "ìµœì‹  ê³µì§€ì‚¬í•­ì„ ë³´ì—¬ì¤˜"),
    
    # íƒ€ì„ì•„ì›ƒ ê²½ê³„ í…ŒìŠ¤íŠ¸
    ("ë³µí•©_ê³ ê¸‰_1", "ë‚´ë…„ 1í•™ê¸° ìˆ˜ê°•ì‹ ì²­í•  ê³¼ëª© 5ê°œ ì¶”ì²œí•˜ê³  ê´€ë ¨ ê³µì§€ì‚¬í•­ë„ ì•Œë ¤ì¤„ë˜?"),
    ("ë³µí•©_ê³ ê¸‰_2", "CS ê³¼ëª©ë“¤ ì¤‘ ê³ í•™ì  ë‚˜ì˜¨ ê³¼ëª©ê³¼ í•´ë‹¹ ì‹œê°„ì— ê°•ì˜ì‹¤ ìœ„ì¹˜ ì•Œë ¤ì¤„ë˜?"),
]

# Redis ì—°ê²°
redis_client = None


def init_redis():
    """Redis ì—°ê²° ì´ˆê¸°í™”"""
    global redis_client
    try:
        redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
        redis_client.ping()
        return True
    except Exception as e:
        print(f"âš ï¸  Redis ì—°ê²° ì‹¤íŒ¨: {e}")
        return False


def get_redis_stats() -> Dict:
    """Redis ìºì‹œ í†µê³„ ìˆ˜ì§‘"""
    if not redis_client:
        return {"available": False}
    
    try:
        info = redis_client.info('stats')
        keys_count = redis_client.dbsize()
        
        return {
            "available": True,
            "total_connections_received": info.get('total_connections_received', 0),
            "total_commands_processed": info.get('total_commands_processed', 0),
            "expired_keys": info.get('expired_keys', 0),
            "evicted_keys": info.get('evicted_keys', 0),
            "db_keys": keys_count,
            "used_memory": info.get('used_memory_human', 'N/A'),
        }
    except Exception as e:
        print(f"âš ï¸  Redis í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {"available": False, "error": str(e)}


async def test_chat_with_metrics(
    session: aiohttp.ClientSession, 
    query_name: str, 
    message: str,
    redis_before: dict
) -> dict:
    """ë„êµ¬ í˜¸ì¶œ ìƒì„¸ ë¶„ì„ì„ í¬í•¨í•œ ì±„íŒ… í…ŒìŠ¤íŠ¸"""
    url = "http://localhost:8000/api/chat"
    payload = {"message": message}
    
    redis_after = {}
    start_time = time.perf_counter()
    
    try:
        async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=60)) as resp:
            elapsed_ms = int((time.perf_counter() - start_time) * 1000)
            
            if resp.status == 200:
                data = await resp.json()
                
                # Redis ìƒíƒœ ìˆ˜ì§‘ (ì‘ë‹µ í›„)
                if redis_client:
                    redis_after = get_redis_stats()
                
                # ë„êµ¬ í˜¸ì¶œ ë¶„ì„
                tool_calls = []
                tool_call_count = 0
                if "tool_calls" in data:
                    tool_calls = data["tool_calls"]
                    tool_call_count = len(tool_calls)
                elif isinstance(data.get("message"), str):
                    # ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ ì¶”ì •
                    msg = data["message"]
                    if "classroom" in msg.lower():
                        tool_calls.append("classroom")
                    if "meal" in msg.lower() or "menu" in msg.lower():
                        tool_calls.append("meal")
                    if "notice" in msg.lower() or "ê³µì§€" in msg.lower():
                        tool_calls.append("notice")
                    if "curriculum" in msg.lower() or "ê³¼ëª©" in msg.lower() or "êµê³¼" in msg.lower():
                        tool_calls.append("curriculum")
                    if "library" in msg.lower() or "ë„ì„œê´€" in msg.lower():
                        tool_calls.append("library")
                    tool_call_count = len(tool_calls)
                
                # ìºì‹œ ì ì¤‘ ê²€ì¦ (ê°™ì€ ì¿¼ë¦¬ë©´ ë” ë¹¨ë¼ì•¼ í•¨)
                cache_hit = None
                if redis_before and redis_after:
                    try:
                        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ì‘ë‹µì‹œê°„ì´ ì´ì „ë³´ë‹¤ 30% ì´ìƒ ë¹ ë¥´ë©´ ìºì‹œ íˆíŠ¸ ì¶”ì •
                        if "prev_latency_ms" in redis_before:
                            ratio = elapsed_ms / redis_before["prev_latency_ms"]
                            cache_hit = ratio < 0.7
                    except:
                        pass
                
                return {
                    "query_name": query_name,
                    "message": message,
                    "status": resp.status,
                    "success": True,
                    "latency_ms": elapsed_ms,
                    "response_length": len(data.get("message", "")),
                    "tool_calls": tool_calls,
                    "tool_call_count": tool_call_count,
                    "cache_hit_estimated": cache_hit,
                }
            else:
                return {
                    "query_name": query_name,
                    "message": message,
                    "status": resp.status,
                    "success": False,
                    "latency_ms": elapsed_ms,
                    "error": f"HTTP {resp.status}",
                    "tool_calls": [],
                    "tool_call_count": 0,
                }
    except asyncio.TimeoutError:
        elapsed_ms = int((time.perf_counter() - start_time) * 1000)
        return {
            "query_name": query_name,
            "message": message,
            "success": False,
            "latency_ms": elapsed_ms,
            "error": "Timeout (60s)",
            "tool_calls": [],
            "tool_call_count": 0,
        }
    except Exception as e:
        elapsed_ms = int((time.perf_counter() - start_time) * 1000)
        return {
            "query_name": query_name,
            "message": message,
            "success": False,
            "latency_ms": elapsed_ms,
            "error": str(e)[:100],
            "tool_calls": [],
            "tool_call_count": 0,
        }


async def main():
    """ì¢…í•© ì„±ëŠ¥ ì§€í‘œ ì¸¡ì •"""
    print("ğŸš€ ì¢…í•© ì„±ëŠ¥ ì§€í‘œ ì¸¡ì • ì‹œì‘\n")
    
    # Redis ì´ˆê¸°í™”
    redis_available = init_redis()
    print(f"{'âœ…' if redis_available else 'âš ï¸ '} Redis: {'ì—°ê²°ë¨' if redis_available else 'ë¯¸ì—°ê²°'}\n")
    
    redis_before = get_redis_stats() if redis_available else {}
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print(f"ğŸ“ {len(SPECIALIZED_QUERIES)}ê°œ íŠ¹í™” ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...\n")
    
    all_results = []
    prev_latency = 0
    
    async with aiohttp.ClientSession() as session:
        for query_name, message in SPECIALIZED_QUERIES:
            redis_state = {"prev_latency_ms": prev_latency}
            redis_state.update(redis_before)
            
            print(f"  â–¸ {query_name}: '{message[:40]}...'", end=" ", flush=True)
            result = await test_chat_with_metrics(session, query_name, message, redis_state)
            all_results.append(result)
            
            if result["success"]:
                tool_str = f"(ë„êµ¬: {', '.join(result['tool_calls'][:2])})" if result['tool_calls'] else "(ë„êµ¬ ì—†ìŒ)"
                cache_str = " [ìºì‹œ?]" if result.get("cache_hit_estimated") else ""
                print(f"âœ… {result['latency_ms']}ms {tool_str}{cache_str}")
                prev_latency = result['latency_ms']
            else:
                print(f"âŒ {result['latency_ms']}ms ({result.get('error', 'Unknown')})")
    
    # Redis ìµœì¢… ìƒíƒœ
    redis_after = get_redis_stats() if redis_available else {}
    
    # í†µê³„ ê³„ì‚°
    success_results = [r for r in all_results if r["success"]]
    failed_results = [r for r in all_results if not r["success"]]
    
    print(f"\n{'=' * 80}")
    print("ğŸ“Š ì„±ëŠ¥ ì§€í‘œ ë¶„ì„")
    print("=" * 80)
    
    # 1. Tool í˜¸ì¶œ ì„±ê³µë¥ 
    print(f"\n1ï¸âƒ£  Tool í˜¸ì¶œ ì„±ê³µë¥ ")
    tool_stats = {}
    for result in success_results:
        for tool in result['tool_calls']:
            if tool not in tool_stats:
                tool_stats[tool] = {"success": 0, "total": 0}
            tool_stats[tool]["success"] += 1
            tool_stats[tool]["total"] += 1
    
    if tool_stats:
        for tool, stats in sorted(tool_stats.items()):
            rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
            print(f"   {tool}: {stats['success']}/{stats['total']} ({rate:.0f}%)")
    else:
        print("   (ë„êµ¬ í˜¸ì¶œ ë°ì´í„° ì—†ìŒ)")
    
    # 2. ìºì‹œ ì ì¤‘ë¥  ì¶”ì •
    print(f"\n2ï¸âƒ£  ìºì‹œ ì ì¤‘ë¥  (ì¶”ì •)")
    cache_hits = sum(1 for r in success_results if r.get('cache_hit_estimated'))
    cache_candidates = sum(1 for r in success_results if r.get('cache_hit_estimated') is not None)
    if cache_candidates > 0:
        cache_rate = cache_hits / cache_candidates * 100
        print(f"   ì¶”ì • íˆíŠ¸: {cache_hits}/{cache_candidates} ({cache_rate:.0f}%)")
    else:
        print(f"   Redis ì—°ê²°: {'âœ…' if redis_available else 'âŒ'}")
        if redis_available:
            print(f"   Redis ë©”ëª¨ë¦¬: {redis_after.get('used_memory', 'N/A')}")
            print(f"   DB í‚¤ ê°œìˆ˜: {redis_after.get('db_keys', 0)}")
    
    # 3. ì¡¸ì—…ìš”ê±´ ì‘ë‹µ ì‹œê°„
    print(f"\n3ï¸âƒ£  ì¡¸ì—…ìš”ê±´ í™•ì¸ ì‘ë‹µ ì‹œê°„")
    graduation_results = [r for r in success_results if "ì¡¸ì—…" in r['query_name']]
    if graduation_results:
        times = [r['latency_ms'] for r in graduation_results]
        print(f"   í˜¸ì¶œ: {len(times)}, í‰ê· : {int(mean(times))}ms, ë²”ìœ„: {min(times)}~{max(times)}ms")
    else:
        print("   (ë°ì´í„° ì—†ìŒ)")
    
    # 4. íƒ€ì„ì•„ì›ƒ ë° ì˜¤ë¥˜ìœ¨
    print(f"\n4ï¸âƒ£  ì˜¤ë¥˜ ë° íƒ€ì„ì•„ì›ƒ ë¶„ì„")
    timeout_count = sum(1 for r in failed_results if "Timeout" in r.get('error', ''))
    other_errors = len(failed_results) - timeout_count
    error_rate = (len(failed_results) / len(all_results) * 100) if all_results else 0
    
    print(f"   ì´ ìš”ì²­: {len(all_results)}")
    print(f"   ì„±ê³µ: {len(success_results)} ({(len(success_results)/len(all_results)*100):.0f}%)")
    print(f"   íƒ€ì„ì•„ì›ƒ: {timeout_count}")
    print(f"   ê¸°íƒ€ ì˜¤ë¥˜: {other_errors}")
    print(f"   ì˜¤ë¥˜ìœ¨: {error_rate:.1f}%")
    
    # 5. MCP ì„œë²„ë³„ ì„±ëŠ¥ (ë„êµ¬ë³„ ì‘ë‹µì‹œê°„)
    if tool_stats:
        print(f"\n5ï¸âƒ£  ë„êµ¬ë³„ í‰ê·  ì‘ë‹µ ì‹œê°„")
        tool_times = {}
        for result in success_results:
            for tool in result['tool_calls']:
                if tool not in tool_times:
                    tool_times[tool] = []
                tool_times[tool].append(result['latency_ms'])
        
        for tool in sorted(tool_times.keys()):
            times = tool_times[tool]
            print(f"   {tool}: {int(mean(times))}ms (ë²”ìœ„: {min(times)}~{max(times)}ms)")
    
    # 6. ì‘ë‹µ ì‹œê°„ ë¶„í¬
    print(f"\n6ï¸âƒ£  ì‘ë‹µ ì‹œê°„ ë¶„í¬")
    if success_results:
        latencies = [r['latency_ms'] for r in success_results]
        print(f"   í‰ê· : {int(mean(latencies))}ms")
        print(f"   ì¤‘ì•™ê°’: {int(median(latencies))}ms")
        print(f"   P95: {int(sorted(latencies)[int(len(latencies)*0.95)])}ms" if len(latencies) > 1 else "   P95: N/A")
        print(f"   ë²”ìœ„: {min(latencies)}~{max(latencies)}ms")
    
    # íŒŒì¼ ì €ì¥
    logs_dir = Path(__file__).resolve().parent.parent / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    out_json = logs_dir / f"comprehensive_metrics_{ts}.json"
    with open(out_json, "w", encoding="utf-8") as f:
        json.dump({
            "generated_at": datetime.now().isoformat(),
            "test_queries": len(all_results),
            "success_count": len(success_results),
            "failed_count": len(failed_results),
            "tool_statistics": tool_stats,
            "cache_hit_rate": (cache_hits / cache_candidates * 100) if cache_candidates > 0 else None,
            "error_rate": error_rate,
            "redis_before": redis_before,
            "redis_after": redis_after,
            "results": all_results,
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'=' * 80}")
    print(f"âœ… ì¸¡ì • ì™„ë£Œ")
    print(f"ğŸ“ ê²°ê³¼: {out_json}")


if __name__ == "__main__":
    asyncio.run(main())
