import json
import time
import pathlib
import subprocess
from datetime import datetime


API_BASE = "http://localhost:8000"
STUDENT_ID = "2019110635"
PASSWORD = "garen@0302"


def login() -> str:
    resp = subprocess.check_output([
        'curl','-s','-X','POST', f'{API_BASE}/api/auth/login',
        '-H','Content-Type: application/x-www-form-urlencoded',
        '-d', f'username={STUDENT_ID}&password={PASSWORD}'
    ], text=True)
    token = json.loads(resp)['access_token']
    return token


def run_chat(token: str, message: str) -> dict:
    payload = json.dumps({"message": message}, ensure_ascii=False)
    start = time.perf_counter()
    resp = subprocess.check_output([
        'curl','-s','-X','POST', f'{API_BASE}/api/chat',
        '-H', f'Authorization: Bearer {token}',
        '-H', 'Content-Type: application/json',
        '-d', payload
    ], text=True)
    elapsed_ms = int((time.perf_counter() - start) * 1000)
    try:
        data = json.loads(resp)
    except Exception:
        data = {"raw": resp}
    return {"latency_ms": elapsed_ms, "response": data}


def build_questions() -> list[dict]:
    q = []
    # ê³µì§€ (10)
    q += [
        {"cat": "notice", "q": "ì»´í“¨í„°ê³µí•™ë¶€ ìµœì‹  ê³µì§€ 3ê°œ ì•Œë ¤ì¤˜"},
        {"cat": "notice", "q": "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©í•™ê³¼ ìµœì‹  ê³µì§€ 5ê°œ"},
        {"cat": "notice", "q": "ì¥í•™ ê´€ë ¨ ê³µì§€ ì°¾ì•„ì¤˜"},
        {"cat": "notice", "q": "íœ´í•™ ê³µì§€ ìˆì–´?"},
        {"cat": "notice", "q": "ì¡¸ì—…ë…¼ë¬¸ ì•ˆë‚´ ê³µì§€ ë³´ì—¬ì¤˜"},
        {"cat": "notice", "q": "ëŒ€íšŒ ëª¨ì§‘ ê³µì§€ ì•Œë ¤ì¤˜"},
        {"cat": "notice", "q": "ì™¸êµ­ì¸ ìœ í•™ìƒ ê³µì§€ ìš”ì•½"},
        {"cat": "notice", "q": "ìˆ˜ê°•ì‹ ì²­ ê´€ë ¨ ìµœì‹  ê³µì§€"},
        {"cat": "notice", "q": "í•™ì‚¬ ì¼ì • ê³µì§€ ê²€ìƒ‰"},
        {"cat": "notice", "q": "ìº¡ìŠ¤í†¤ ê³µì§€ ìˆë‹ˆ?"},
    ]

    # í•™ì‹ (10)
    q += [
        {"cat": "meal", "q": "ì˜¤ëŠ˜ í•™ìƒíšŒê´€ í•™ì‹ ë­ ë‚˜ì™€?"},
        {"cat": "meal", "q": "ì˜¤ëŠ˜ ì €ë… ë©”ë‰´ ì•Œë ¤ì¤˜"},
        {"cat": "meal", "q": "ë¶ˆê³ ê¸° ì–¸ì œ ë‚˜ì™€?"},
        {"cat": "meal", "q": "ë¹„ê±´ ë©”ë‰´ ìˆì–´?"},
        {"cat": "meal", "q": "ì¹´ë ˆ ë‚˜ì˜¤ëŠ” ë‚  ì°¾ì•„ì¤˜"},
        {"cat": "meal", "q": "ì´ë²ˆ ì£¼ ì¸ê¸° ë©”ë‰´ ì¶”ì²œ"},
        {"cat": "meal", "q": "ëˆê¹ŒìŠ¤ ë©”ë‰´ ê²€ìƒ‰"},
        {"cat": "meal", "q": "ë¼ë©´ ê°€ëŠ¥í•œê°€ìš”?"},
        {"cat": "meal", "q": "í•™ì‹ ê°€ê²© ì•Œë ¤ì¤˜"},
        {"cat": "meal", "q": "í•™ìƒíšŒê´€ ì‹ë‹¹ ì •ë³´ ì•Œë ¤ì¤˜"},
    ]

    # ë„ì„œê´€ (10)
    q += [
        {"cat": "library", "q": "êµ­ì œìº í¼ìŠ¤ ë„ì„œê´€ ìš´ì˜ì‹œê°„ ì•Œë ¤ì¤˜"},
        {"cat": "library", "q": "ë„ì„œê´€ ì¢Œì„ í˜„í™© ë³¼ ìˆ˜ ìˆì–´?"},
        {"cat": "library", "q": "ë„ì„œê´€ ì˜ˆì•½ ë§í¬ ì•Œë ¤ì¤˜"},
        {"cat": "library", "q": "ì‹œí—˜ê¸°ê°„ ì—°ì¥ ìš´ì˜í•˜ë‹ˆ?"},
        {"cat": "library", "q": "ë„ì„œê´€ ìœ„ì¹˜ì™€ ì „í™”ë²ˆí˜¸ ì•Œë ¤ì¤˜"},
        {"cat": "library", "q": "ì—´ëŒì‹¤ ì¢Œì„ ì˜ˆì•½ ë°©ë²• ì•Œë ¤ì¤˜"},
        {"cat": "library", "q": "ì„œìš¸ ìº í¼ìŠ¤ ë„ì„œê´€ë„ ì•Œë ¤ì¤˜"},
        {"cat": "library", "q": "ì „ììë£Œì‹¤ ì´ìš© ê°€ëŠ¥ ì‹œê°„"},
        {"cat": "library", "q": "ë„ì„œê´€ ì´ìš© ìˆ˜ì¹™ ìš”ì•½í•´ì¤˜"},
        {"cat": "library", "q": "ë…¸íŠ¸ë¶ëŒ€ì—¬ ê°€ëŠ¥í•´?"},
    ]

    # ê°•ì˜ì‹¤ (5)
    q += [
        {"cat": "classroom", "q": "ì „ìì •ë³´ëŒ€í•™ê´€ 312 ì–´ë””ì•¼?"},
        {"cat": "classroom", "q": "ì»´í“¨í„°ê³µí•™ ì‹¤ìŠµì‹¤ ìœ„ì¹˜ ì•Œë ¤ì¤˜"},
        {"cat": "classroom", "q": "ì—˜ë¦¬ë² ì´í„° ìˆëŠ” ê°•ì˜ì‹¤ì´ ì–´ë””ì•¼?"},
        {"cat": "classroom", "q": "êµìˆ˜ë‹˜ ì—°êµ¬ì‹¤ ì°¾ê³  ì‹¶ì–´"},
        {"cat": "classroom", "q": "ê°•ì˜ì‹¤ 201 ê°€ëŠ” ê¸¸ ì•Œë ¤ì¤˜"},
    ]

    # êµê³¼ê³¼ì •/ì¡¸ì—…ìš”ê±´ (10)
    q += [
        {"cat": "curriculum", "q": "ìë£Œêµ¬ì¡° êµê³¼ê³¼ì • ê³¼ëª© ìˆì–´?"},
        {"cat": "curriculum", "q": "2024ë…„ 1í•™ê¸° ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ëŒ€í•™ êµê³¼ê³¼ì • ê³¼ëª© ë³´ì—¬ì¤˜"},
        {"cat": "curriculum", "q": "ì „ê³µ í•„ìˆ˜ ê³¼ëª©ë§Œ ëª¨ì•„ì„œ ë³´ì—¬ì¤˜"},
        {"cat": "curriculum", "q": "AI ê´€ë ¨ ê³¼ëª© ì°¾ì•„ì¤˜"},
        {"cat": "curriculum", "q": "í´ë¼ìš°ë“œ ìˆ˜ì—… ìˆì–´?"},
        {"cat": "curriculum", "q": "í”„ë¡œê·¸ë˜ë°ì–¸ì–´ë¡  ê°œì„¤ ì—¬ë¶€"},
        {"cat": "curriculum", "q": "ì¡¸ì—…ìš”ê±´ ì•Œë ¤ì¤˜"},
        {"cat": "curriculum", "q": "ì¡¸ì—… ì§„í–‰ë„ í‰ê°€í•´ì¤˜: CSE103,CSE204,CSE305 ì´ìˆ˜"},
        {"cat": "curriculum", "q": "í”„ë¡œê·¸ë¨ ëª©ë¡ ë³´ì—¬ì¤˜"},
        {"cat": "curriculum", "q": "1í•™ê¸°ì—ë§Œ ì—¬ëŠ” ê³¼ëª©ì´ ë­ì•¼?"},
    ]

    # ì¼ë°˜ ì•ˆë‚´ (5)
    q += [
        {"cat": "general", "q": "ì»´í“¨í„°ê³µí•™ë¶€ ì†Œê°œ ê°„ë‹¨íˆ í•´ì¤˜"},
        {"cat": "general", "q": "ì „ê³µ ì¶”ì²œ íŠ¸ë™ ì•Œë ¤ì¤˜"},
        {"cat": "general", "q": "ì½”ë”© ìŠ¤í„°ë”” ì–´ë–»ê²Œ ì‹œì‘í•´?"},
        {"cat": "general", "q": "ì‹œí—˜ê¸°ê°„ ê³µë¶€ íŒ"},
        {"cat": "general", "q": "ì·¨ì—… ì¤€ë¹„ ë¡œë“œë§µ"},
    ]

    return q


def derive_metrics(item: dict) -> dict:
    r = item.get("response", {})
    msg = r.get("message", "") or ""
    metrics = {
        "message_len": len(msg),
        "has_notices": bool(r.get("notices")),
        "has_meals": bool(r.get("meals")),
        "has_library_info": bool(r.get("show_library_info")) or bool(r.get("library_info")),
        "has_curriculum": bool(r.get("curriculum_courses")) or bool(r.get("courses")),
        "error": r.get("error") or r.get("error_message")
    }
    return metrics


def main():
    root = pathlib.Path(__file__).resolve().parents[1]
    logs_dir = root / 'logs'
    logs_dir.mkdir(parents=True, exist_ok=True)

    token = login()
    questions = build_questions()

    results = []
    start_all = time.perf_counter()
    for idx, item in enumerate(questions, 1):
        out = run_chat(token, item["q"])
        metrics = derive_metrics(out)
        results.append({
            "idx": idx,
            "category": item["cat"],
            "question": item["q"],
            "latency_ms": out["latency_ms"],
            "metrics": metrics,
            "response": out["response"],
        })

    total_ms = int((time.perf_counter() - start_all) * 1000)

    summary = {
        "generated_at": datetime.now().isoformat(),
        "total_questions": len(questions),
        "total_time_ms": total_ms,
        "avg_latency_ms": int(sum(r["latency_ms"] for r in results) / len(results)),
        "by_category": {},
    }

    # ì¹´í…Œê³ ë¦¬ í†µê³„
    from collections import defaultdict
    cat = defaultdict(list)
    for r in results:
        cat[r["category"]].append(r["latency_ms"])
    for k, v in cat.items():
        summary["by_category"][k] = {
            "count": len(v),
            "avg_latency_ms": int(sum(v)/len(v)),
            "p95_latency_ms": sorted(v)[int(len(v)*0.95)-1] if v else 0,
        }

    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    out_json = logs_dir / f'comprehensive_run_{ts}.json'
    out_txt = logs_dir / f'comprehensive_summary_{ts}.txt'

    with open(out_json, 'w', encoding='utf-8') as f:
        json.dump({"summary": summary, "items": results}, f, ensure_ascii=False, indent=2)

    # ê°„ëµ í…ìŠ¤íŠ¸ ìš”ì•½
    lines = [
        f"ì´ {summary['total_questions']}ë¬¸í•­, ì´ {summary['total_time_ms']}ms, í‰ê·  {summary['avg_latency_ms']}ms",
        "ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì§€ì—°(ms):" 
    ]
    for k, v in summary["by_category"].items():
        lines.append(f" - {k}: avg {v['avg_latency_ms']} (p95 {v['p95_latency_ms']})")
    lines.append("")
    for r in results:
        lines.append(f"[{r['category']}] {r['question']} -> {r['latency_ms']}ms, msg_len={r['metrics']['message_len']}")

    out_txt.write_text("\n".join(lines), encoding='utf-8')

    print(f"saved: {out_json}")
    print(f"saved: {out_txt}")


if __name__ == '__main__':
    main()
"""
ì¢…í•© MCP í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  MCP ì„œë²„ë¥¼ ì´ë™ì›í•œ 50ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
"""
import json
import subprocess
import time
from datetime import datetime
from pathlib import Path
import statistics

# ë¡œê·¸ì¸ í† í° ë°œê¸‰
def get_token():
    result = subprocess.check_output([
        'curl', '-s', '-X', 'POST', 'http://localhost:8000/api/auth/login',
        '-H', 'Content-Type: application/x-www-form-urlencoded',
        '-d', 'username=2019110635&password=garen@0302'
    ], text=True)
    return json.loads(result)['access_token']

# ì§ˆë¬¸ ì‹¤í–‰ ë° ì¸¡ì •
def execute_query(token, question):
    payload = json.dumps({"message": question}, ensure_ascii=False)
    
    start_time = time.time()
    try:
        result = subprocess.check_output([
            'curl', '-s', '-X', 'POST', 'http://localhost:8000/api/chat',
            '-H', f'Authorization: Bearer {token}',
            '-H', 'Content-Type: application/json',
            '-d', payload,
            '--max-time', '20'
        ], text=True, timeout=25)
        
        end_time = time.time()
        latency_ms = int((end_time - start_time) * 1000)
        
        try:
            parsed = json.loads(result)
            success = True
            error = None
        except Exception as e:
            parsed = {"raw": result}
            success = False
            error = str(e)
        
        # MCP íˆ´ ì‚¬ìš© ì¶”ì¶œ
        mcp_tools = []
        if parsed.get('notices'):
            mcp_tools.append('notice')
        if parsed.get('meals'):
            mcp_tools.append('meal')
        if parsed.get('library_info') or parsed.get('library_seats'):
            mcp_tools.append('library')
        if parsed.get('curriculum_courses') or parsed.get('requirements'):
            mcp_tools.append('curriculum')
        if parsed.get('courses'):
            mcp_tools.append('course')
        if parsed.get('classroom'):
            mcp_tools.append('classroom')
        
        return {
            "question": question,
            "response": parsed,
            "latency_ms": latency_ms,
            "latency_sec": round(latency_ms / 1000, 2),
            "success": success,
            "error": error,
            "response_length": len(parsed.get('message', '')),
            "mcp_tools_used": list(set(mcp_tools)),
            "has_structured_data": any([
                parsed.get('notices'),
                parsed.get('meals'),
                parsed.get('library_info'),
                parsed.get('curriculum_courses'),
                parsed.get('courses'),
                parsed.get('classroom')
            ]),
            "timestamp": datetime.now().isoformat()
        }
    except subprocess.TimeoutExpired:
        return {
            "question": question,
            "response": {"error": "timeout"},
            "latency_ms": 25000,
            "latency_sec": 25.0,
            "success": False,
            "error": "Request timeout (25s)",
            "response_length": 0,
            "mcp_tools_used": [],
            "has_structured_data": False,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "question": question,
            "response": {"error": str(e)},
            "latency_ms": 0,
            "latency_sec": 0,
            "success": False,
            "error": str(e),
            "response_length": 0,
            "mcp_tools_used": [],
            "has_structured_data": False,
            "timestamp": datetime.now().isoformat()
        }

# 50ê°œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ (ë‹¤ì–‘í•œ MCP í™œìš©) - ë¹ ë¥¸ ë²„ì „
questions = [
    # Notice MCP (8ê°œ)
    "ì»´ê³µ ìµœì‹  ê³µì§€ 3ê°œ",
    "ì†Œìœµê³¼ ê³µì§€ 2ê°œ",
    "ì „ìê³µí•™ê³¼ ê³µì§€",
    "ì¥í•™ê¸ˆ ê³µì§€ ìˆì–´?",
    "ì¡¸ì—… ê´€ë ¨ ê³µì§€",
    "ì·¨ì—… ê³µì§€",
    "ëŒ€íšŒ ê³µì§€",
    "ìˆ˜ê°•ì‹ ì²­ ê³µì§€",
    
    # Meal MCP (8ê°œ)
    "ì˜¤ëŠ˜ í•™ì‹",
    "ì ì‹¬ ë©”ë‰´",
    "ì €ë… í•™ì‹",
    "ëˆê¹ŒìŠ¤ ì–¸ì œ?",
    "ê¹€ì¹˜ì°Œê°œ ë‚˜ì™€?",
    "ì¹˜í‚¨ ë©”ë‰´",
    "í•™ì‹ ê°€ê²©",
    "ì‹ë‹¹ ì‹œê°„",
    
    # Library MCP (8ê°œ)
    "ë„ì„œê´€ ìš´ì˜ì‹œê°„",
    "ì„œìš¸ìº  ë„ì„œê´€",
    "ì¤‘ì•™ë„ì„œê´€ ìœ„ì¹˜",
    "ë„ì„œê´€ ì „í™”ë²ˆí˜¸",
    "ë„ì„œê´€ ì¸µë³„ ì•ˆë‚´",
    "ë„ì„œê´€ í‰ì¼ ì‹œê°„",
    "ë„ì„œê´€ ì£¼ë§",
    "ì¢Œì„ ì˜ˆì•½ ë°©ë²•",
    
    # Curriculum MCP (8ê°œ)
    "2024ë…„ 1í•™ê¸° êµê³¼ê³¼ì •",
    "2í•™ê¸° ê°œì„¤ ê³¼ëª©",
    "ì»¤ë¦¬í˜ëŸ¼",
    "ì „ê³µí•„ìˆ˜",
    "ì¡¸ì—…ìš”ê±´",
    "ì „ê³µ í•µì‹¬",
    "1í•™ê¸° ê³¼ëª© ì¶”ì²œ",
    "ì¡¸ì—… í•™ì ",
    
    # Course MCP (9ê°œ)
    "ì»´ê³µ ê³¼ëª©",
    "ì†Œìœµê³¼ ê³¼ëª©",
    "ë”¥ëŸ¬ë‹ ê³¼ëª©",
    "ì›¹í”„ë¡œê·¸ë˜ë°",
    "ì•Œê³ ë¦¬ì¦˜ ìˆ˜ì—…",
    "ìë£Œêµ¬ì¡° ê³¼ëª©",
    "ë°ì´í„°ë² ì´ìŠ¤",
    "ìš´ì˜ì²´ì œ",
    "ë„¤íŠ¸ì›Œí¬ ê³¼ëª©",
    
    # Classroom MCP (9ê°œ)
    "ì „ìì •ë³´ëŒ€",
    "401í˜¸",
    "êµìˆ˜ì—°êµ¬ì‹¤",
    "í¸ì˜ì‹œì„¤",
    "ì „ì •ëŒ€ ì¸µìˆ˜",
    "ê°•ì˜ì‹¤ ì°¾ê¸°",
    "201í˜¸ ìœ„ì¹˜",
    "ì»´ì‹¤ ì–´ë””",
    "ì‹¤ìŠµì‹¤"
]

def main():
    print("=" * 60)
    print("ğŸš€ ì¢…í•© MCP í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“Š ì´ ì§ˆë¬¸ ìˆ˜: {len(questions)}ê°œ")
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # í† í° ë°œê¸‰
    print("\nğŸ”‘ ë¡œê·¸ì¸ í† í° ë°œê¸‰ ì¤‘...")
    token = get_token()
    print("âœ… í† í° ë°œê¸‰ ì™„ë£Œ")
    
    # ì§ˆë¬¸ ì‹¤í–‰
    results = []
    for idx, question in enumerate(questions, 1):
        print(f"\n[{idx}/{len(questions)}] ì§ˆë¬¸: {question}")
        result = execute_query(token, question)
        results.append(result)
        
        status = "âœ… ì„±ê³µ" if result['success'] else "âŒ ì‹¤íŒ¨"
        print(f"    {status} | {result['latency_ms']}ms | MCP: {', '.join(result['mcp_tools_used']) or 'None'}")
        
        # ì§„í–‰ í‘œì‹œ
        if idx % 10 == 0:
            print(f"\nğŸ“Š ì§„í–‰ë¥ : {idx}/{len(questions)} ({round(idx/len(questions)*100, 1)}%)")
        
        # ì†ë„ ì œí•œ ë°©ì§€ (ê°„ê²© ì¤„ì„)
        time.sleep(0.2)
    
    # í†µê³„ ê³„ì‚°
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    latencies = [r['latency_ms'] for r in successful]
    avg_latency = statistics.mean(latencies) if latencies else 0
    median_latency = statistics.median(latencies) if latencies else 0
    min_latency = min(latencies) if latencies else 0
    max_latency = max(latencies) if latencies else 0
    
    mcp_usage = {}
    for result in successful:
        for mcp in result['mcp_tools_used']:
            mcp_usage[mcp] = mcp_usage.get(mcp, 0) + 1
    
    summary = {
        "test_info": {
            "total_questions": len(questions),
            "success_count": len(successful),
            "failure_count": len(failed),
            "success_rate": round(len(successful) / len(questions) * 100, 2),
            "start_time": results[0]['timestamp'] if results else None,
            "end_time": results[-1]['timestamp'] if results else None
        },
        "latency_stats": {
            "average_ms": round(avg_latency, 2),
            "median_ms": round(median_latency, 2),
            "min_ms": min_latency,
            "max_ms": max_latency,
            "average_sec": round(avg_latency / 1000, 2),
            "median_sec": round(median_latency / 1000, 2)
        },
        "mcp_usage": mcp_usage,
        "response_stats": {
            "avg_response_length": round(statistics.mean([r['response_length'] for r in successful]), 2) if successful else 0,
            "structured_data_count": len([r for r in successful if r['has_structured_data']]),
            "structured_data_rate": round(len([r for r in successful if r['has_structured_data']]) / len(successful) * 100, 2) if successful else 0
        }
    }
    
    # ê²°ê³¼ ì €ì¥
    output = {
        "summary": summary,
        "detailed_results": results
    }
    
    output_path = Path('/Users/jung-yoonsuh/Desktop/agent-khu/logs/comprehensive_test_results.json')
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(output, ensure_ascii=False, indent=2))
    
    # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    report_lines = [
        "=" * 80,
        "ğŸ“Š ì¢…í•© MCP í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸",
        "=" * 80,
        "",
        "## ğŸ“ˆ ì „ì²´ í†µê³„",
        f"- ì´ ì§ˆë¬¸ ìˆ˜: {summary['test_info']['total_questions']}ê°œ",
        f"- ì„±ê³µ: {summary['test_info']['success_count']}ê°œ ({summary['test_info']['success_rate']}%)",
        f"- ì‹¤íŒ¨: {summary['test_info']['failure_count']}ê°œ",
        "",
        "## â±ï¸ ì‘ë‹µ ì†ë„",
        f"- í‰ê· : {summary['latency_stats']['average_sec']}ì´ˆ ({summary['latency_stats']['average_ms']}ms)",
        f"- ì¤‘ì•™ê°’: {summary['latency_stats']['median_sec']}ì´ˆ ({summary['latency_stats']['median_ms']}ms)",
        f"- ìµœì†Œ: {summary['latency_stats']['min_ms']}ms",
        f"- ìµœëŒ€: {summary['latency_stats']['max_ms']}ms",
        "",
        "## ğŸ”§ MCP ì„œë²„ ì‚¬ìš© í†µê³„",
    ]
    
    for mcp, count in sorted(mcp_usage.items(), key=lambda x: x[1], reverse=True):
        report_lines.append(f"- {mcp}: {count}íšŒ")
    
    report_lines.extend([
        "",
        "## ğŸ“ ì‘ë‹µ í’ˆì§ˆ",
        f"- í‰ê·  ì‘ë‹µ ê¸¸ì´: {summary['response_stats']['avg_response_length']}ì",
        f"- êµ¬ì¡°í™”ëœ ë°ì´í„° í¬í•¨: {summary['response_stats']['structured_data_count']}ê°œ ({summary['response_stats']['structured_data_rate']}%)",
        "",
        "## âŒ ì‹¤íŒ¨í•œ ì§ˆë¬¸ë“¤",
    ])
    
    for result in failed:
        report_lines.append(f"- {result['question']}: {result['error']}")
    
    report_lines.extend([
        "",
        "=" * 80,
        f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ | ê²°ê³¼ ì €ì¥: {output_path}",
        "=" * 80
    ])
    
    report = "\n".join(report_lines)
    
    report_path = Path('/Users/jung-yoonsuh/Desktop/agent-khu/logs/comprehensive_test_report.txt')
    report_path.write_text(report)
    
    print("\n" + report)
    print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼ JSON: {output_path}")
    print(f"ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸: {report_path}")

if __name__ == "__main__":
    main()
