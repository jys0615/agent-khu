"""
í†µí•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
ëª¨ë“  ì„±ëŠ¥ ì§€í‘œë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ì— ì €ì¥
"""
import asyncio
import aiohttp
import json
import time
import redis
from datetime import datetime
from pathlib import Path
from statistics import mean, stdev, median
from typing import Dict, List, Optional

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¸íŠ¸
TEST_QUERIES = {
    # 1. MCP ì„œë²„ ê°œë³„ ì„±ëŠ¥ (E2Eë¥¼ í†µí•œ ê°„ì ‘ ì¸¡ì •)
    "mcp_by_server": {
        "curriculum": [
            "ìë£Œêµ¬ì¡° ê³¼ëª© ìˆì–´?",
            "ì•Œê³ ë¦¬ì¦˜ ê³¼ëª© ì°¾ì•„ì¤˜",
            "í”„ë¡œê·¸ë˜ë° ê³¼ëª© ë­ê°€ ìˆì§€?",
        ],
        "notice": [
            "ìµœì‹  ê³µì§€ì‚¬í•­ì„ ë³´ì—¬ì¤˜",
            "ì¥í•™ê¸ˆ ê³µì§€ì‚¬í•­ ìˆì–´?",
            "í•™ì‚¬ ê³µì§€ì‚¬í•­ ì•Œë ¤ì¤˜",
        ],
        "meal": [
            "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ë­ì•¼?",
            "ì˜¤ëŠ˜ ì €ë… ë©”ë‰´ëŠ”?",
            "ë‚´ì¼ ì•„ì¹¨ ë©”ë‰´ëŠ”?",
        ],
        "classroom": [
            "101í˜¸ ì°¾ì•„ì¤„ë˜?",
            "ì „ìì •ë³´ëŒ€í•™ê´€ ì–´ë””ì•¼?",
            "ê³µí•™ê´€ ê°•ì˜ì‹¤ ì°¾ì•„ì¤˜",
        ],
    },
    
    # 2. E2E ì‘ë‹µ ì‹œê°„
    "e2e_simple_qa": [  # ë„êµ¬ ì—†ìŒ
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ê°ì‚¬í•©ë‹ˆë‹¤",
        "ê²½í¬ëŒ€í•™êµëŠ” ì–´ë””ì— ìˆì–´?",
    ],
    
    "e2e_single_tool": [  # ë‹¨ì¼ ë„êµ¬
        "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ë­ì•¼?",
        "ìµœì‹  ê³µì§€ì‚¬í•­ì„ ë³´ì—¬ì¤˜",
        "101í˜¸ ì°¾ì•„ì¤„ë˜?",
    ],
    
    "e2e_multi_tool": [  # ë³µí•© ì¿¼ë¦¬ (2ê°œ)
        "ìë£Œêµ¬ì¡° ê³¼ëª© ìˆì–´?",
        "ì¥í•™ê¸ˆ ê³µì§€ì‚¬í•­ ìˆì–´?",
        "ì „ìì •ë³´ëŒ€í•™ê´€ ê°•ì˜ì‹¤ì€ ì–´ë”” ìˆì–´?",
    ],
    
    "e2e_advanced": [  # ë³µí•© ê³ ê¸‰ (3ê°œ+)
        "3í•™ê¸° ìˆ˜ê°•í•  ê³¼ëª© ì¶”ì²œí•´ì¤„ë˜?",
        "CS ê´€ë ¨ ê³¼ëª©ë“¤ ë­ê°€ ìˆì§€?",
    ],
    
    # 3. ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    "cache_test": [
        ("ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ë­ì•¼?", 3),  # ê°™ì€ ì¿¼ë¦¬ 3íšŒ
        ("ìµœì‹  ê³µì§€ì‚¬í•­ì„ ë³´ì—¬ì¤˜", 3),
    ],
}

# Redis í´ë¼ì´ì–¸íŠ¸
redis_client = None


def init_redis():
    """Redis ì—°ê²°"""
    global redis_client
    try:
        redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
        redis_client.ping()
        return True
    except:
        return False


async def test_mcp_by_query(server: str, message: str) -> dict:
    """MCP ì„œë²„ë¥¼ ê°„ì ‘ì ìœ¼ë¡œ ì¸¡ì • (E2E í†µí•´)"""
    result = await test_e2e_chat(message)
    result["server"] = server
    return result


async def test_e2e_chat(message: str) -> dict:
    """E2E ì±„íŒ… í…ŒìŠ¤íŠ¸"""
    url = "http://localhost:8000/api/chat"
    payload = {"message": message}
    
    start = time.perf_counter()
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=60)) as resp:
                elapsed_ms = int((time.perf_counter() - start) * 1000)
                
                if resp.status == 200:
                    data = await resp.json()
                    return {
                        "message": message,
                        "success": True,
                        "latency_ms": elapsed_ms,
                        "response_length": len(data.get("message", "")),
                    }
                else:
                    return {
                        "message": message,
                        "success": False,
                        "latency_ms": elapsed_ms,
                        "error": f"HTTP {resp.status}",
                    }
    except asyncio.TimeoutError:
        elapsed_ms = int((time.perf_counter() - start) * 1000)
        return {
            "message": message,
            "success": False,
            "latency_ms": elapsed_ms,
            "error": "Timeout",
        }
    except Exception as e:
        elapsed_ms = int((time.perf_counter() - start) * 1000)
        return {
            "message": message,
            "success": False,
            "latency_ms": elapsed_ms,
            "error": str(e)[:100],
        }


async def run_benchmark():
    """í†µí•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("ğŸš€ í†µí•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘\n")
    print("=" * 80)
    
    results = {
        "generated_at": datetime.now().isoformat(),
        "mcp_performance": {},
        "e2e_performance": {},
        "cache_performance": {},
        "stability": {},
    }
    
    # Redis ì´ˆê¸°í™”
    redis_available = init_redis()
    print(f"Redis: {'âœ… ì—°ê²°' if redis_available else 'âŒ ë¯¸ì—°ê²°'}\n")
    
    # ========================================================================
    # 1. MCP ì„œë²„ ê°œë³„ ì„±ëŠ¥
    # ========================================================================
    print("1ï¸âƒ£  MCP ì„œë²„ ê°œë³„ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
    
    mcp_results = []
    for server, queries in TEST_QUERIES["mcp_by_server"].items():
        print(f"   ğŸ“ {server}...")
        for query in queries:
            print(f"      â–¸ '{query[:30]}...'", end=" ", flush=True)
            result = await test_mcp_by_query(server, query)
            mcp_results.append(result)
            
            if result["success"]:
                print(f"âœ… {result['latency_ms']}ms")
            else:
                print(f"âŒ {result.get('error', 'Unknown')}")
    
    # ì„œë²„ë³„ í†µê³„
    by_server = {}
    for result in mcp_results:
        server = result["server"]
        if server not in by_server:
            by_server[server] = {"latencies": [], "success": 0, "total": 0}
        
        by_server[server]["total"] += 1
        if result["success"]:
            by_server[server]["success"] += 1
            by_server[server]["latencies"].append(result["latency_ms"])
    
    for server, data in by_server.items():
        latencies = data["latencies"]
        results["mcp_performance"][server] = {
            "avg_latency_ms": int(mean(latencies)) if latencies else None,
            "min_latency_ms": min(latencies) if latencies else None,
            "max_latency_ms": max(latencies) if latencies else None,
            "success_rate": (data["success"] / data["total"] * 100) if data["total"] > 0 else 0,
            "total_calls": data["total"],
            "successful_calls": data["success"],
        }
    
    print()
    
    # ========================================================================
    # 2. E2E ì‘ë‹µ ì‹œê°„
    # ========================================================================
    print("2ï¸âƒ£  E2E ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì¤‘...")
    
    # ê°„ë‹¨í•œ QA
    print("   ğŸ“ ê°„ë‹¨í•œ QA (ë„êµ¬ ì—†ìŒ)...")
    simple_results = []
    for msg in TEST_QUERIES["e2e_simple_qa"]:
        print(f"      â–¸ '{msg[:30]}...'", end=" ", flush=True)
        result = await test_e2e_chat(msg)
        simple_results.append(result)
        if result["success"]:
            print(f"âœ… {result['latency_ms']}ms")
        else:
            print(f"âŒ")
    
    # ë‹¨ì¼ ë„êµ¬
    print("   ğŸ“ ë‹¨ì¼ Tool...")
    single_results = []
    for msg in TEST_QUERIES["e2e_single_tool"]:
        print(f"      â–¸ '{msg[:30]}...'", end=" ", flush=True)
        result = await test_e2e_chat(msg)
        single_results.append(result)
        if result["success"]:
            print(f"âœ… {result['latency_ms']}ms")
        else:
            print(f"âŒ")
    
    # ë³µí•© ì¿¼ë¦¬
    print("   ğŸ“ ë³µí•© ì¿¼ë¦¬ (2ê°œ Tool)...")
    multi_results = []
    for msg in TEST_QUERIES["e2e_multi_tool"]:
        print(f"      â–¸ '{msg[:30]}...'", end=" ", flush=True)
        result = await test_e2e_chat(msg)
        multi_results.append(result)
        if result["success"]:
            print(f"âœ… {result['latency_ms']}ms")
        else:
            print(f"âŒ")
    
    # ë³µí•© ê³ ê¸‰
    print("   ğŸ“ ë³µí•© ê³ ê¸‰ (3ê°œ+ Tool)...")
    advanced_results = []
    for msg in TEST_QUERIES["e2e_advanced"]:
        print(f"      â–¸ '{msg[:30]}...'", end=" ", flush=True)
        result = await test_e2e_chat(msg)
        advanced_results.append(result)
        if result["success"]:
            print(f"âœ… {result['latency_ms']}ms")
        else:
            print(f"âŒ")
    
    # E2E í†µê³„
    def calc_stats(results_list):
        success = [r for r in results_list if r["success"]]
        if not success:
            return None
        latencies = [r["latency_ms"] for r in success]
        return {
            "avg_ms": int(mean(latencies)),
            "min_ms": min(latencies),
            "max_ms": max(latencies),
            "median_ms": int(median(latencies)),
            "success_rate": len(success) / len(results_list) * 100,
        }
    
    results["e2e_performance"] = {
        "simple_qa": calc_stats(simple_results),
        "single_tool": calc_stats(single_results),
        "multi_tool": calc_stats(multi_results),
        "advanced": calc_stats(advanced_results),
    }
    
    print()
    
    # ========================================================================
    # 3. ìºì‹œ ì„±ëŠ¥
    # ========================================================================
    print("3ï¸âƒ£  ìºì‹œ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
    
    cache_results = []
    for query, repeat_count in TEST_QUERIES["cache_test"]:
        print(f"   ğŸ“ '{query[:30]}' Ã— {repeat_count}íšŒ...")
        latencies = []
        
        for i in range(repeat_count):
            result = await test_e2e_chat(query)
            if result["success"]:
                latencies.append(result["latency_ms"])
                print(f"      {i+1}íšŒ: {result['latency_ms']}ms")
        
        if latencies:
            cache_results.append({
                "query": query,
                "latencies": latencies,
                "improvement": ((latencies[0] - latencies[-1]) / latencies[0] * 100) if len(latencies) > 1 else 0,
            })
    
    # ìºì‹œ ì ì¤‘ë¥  ì¶”ì •
    total_improvement = 0
    cache_hits = 0
    for item in cache_results:
        if item["improvement"] > 20:  # 20% ì´ìƒ ë¹¨ë¼ì§€ë©´ ìºì‹œë¡œ íŒë‹¨
            cache_hits += 1
        total_improvement += item["improvement"]
    
    results["cache_performance"] = {
        "cache_hit_rate": (cache_hits / len(cache_results) * 100) if cache_results else 0,
        "avg_improvement": total_improvement / len(cache_results) if cache_results else 0,
        "details": cache_results,
    }
    
    print()
    
    # ========================================================================
    # 4. ì•ˆì •ì„±
    # ========================================================================
    print("4ï¸âƒ£  ì•ˆì •ì„± ë¶„ì„...")
    
    all_results = simple_results + single_results + multi_results + advanced_results + mcp_results
    total = len(all_results)
    successful = sum(1 for r in all_results if r.get("success"))
    timeouts = sum(1 for r in all_results if not r.get("success") and "Timeout" in str(r.get("error", "")))
    
    results["stability"] = {
        "tool_call_success_rate": (successful / total * 100) if total > 0 else 0,
        "timeout_count": timeouts,
        "error_rate": ((total - successful) / total * 100) if total > 0 else 0,
        "total_requests": total,
        "successful_requests": successful,
    }
    
    print(f"   ì„±ê³µë¥ : {successful}/{total} ({successful/total*100:.1f}%)")
    print(f"   íƒ€ì„ì•„ì›ƒ: {timeouts}ê±´")
    print(f"   ì˜¤ë¥˜ìœ¨: {(total-successful)/total*100:.1f}%")
    
    # ========================================================================
    # íŒŒì¼ ì €ì¥
    # ========================================================================
    logs_dir = Path(__file__).resolve().parent.parent / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    out_file = logs_dir / f"unified_benchmark_{ts}.json"
    with open(out_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'=' * 80}")
    print(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    print(f"ğŸ“ ê²°ê³¼: {out_file}")
    
    # ìš”ì•½ ì¶œë ¥
    print(f"\n{'=' * 80}")
    print("ğŸ“Š ìš”ì•½")
    print("=" * 80)
    
    print("\n1ï¸âƒ£  MCP ì„œë²„ ê°œë³„ ì„±ëŠ¥:")
    for server, perf in results["mcp_performance"].items():
        if perf["avg_latency_ms"]:
            print(f"   {server:12} | {perf['avg_latency_ms']:5}ms | ì„±ê³µë¥  {perf['success_rate']:.0f}%")
    
    print("\n2ï¸âƒ£  E2E ì‘ë‹µ ì‹œê°„:")
    for category, perf in results["e2e_performance"].items():
        if perf:
            print(f"   {category:12} | {perf['avg_ms']:5}ms | ë²”ìœ„ {perf['min_ms']}~{perf['max_ms']}ms")
    
    print(f"\n3ï¸âƒ£  ìºì‹œ ì„±ëŠ¥:")
    print(f"   ì ì¤‘ë¥ : {results['cache_performance']['cache_hit_rate']:.0f}%")
    print(f"   í‰ê·  ê°œì„ : {results['cache_performance']['avg_improvement']:.0f}%")
    
    print(f"\n4ï¸âƒ£  ì•ˆì •ì„±:")
    print(f"   Tool ì„±ê³µë¥ : {results['stability']['tool_call_success_rate']:.1f}%")
    print(f"   íƒ€ì„ì•„ì›ƒ: {results['stability']['timeout_count']}ê±´")
    print(f"   ì˜¤ë¥˜ìœ¨: {results['stability']['error_rate']:.1f}%")


if __name__ == "__main__":
    asyncio.run(run_benchmark())
